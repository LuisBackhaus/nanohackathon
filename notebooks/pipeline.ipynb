{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7305c976",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U google-genai\n",
    "!pip install Pillow\n",
    "!pip install pydantic\n",
    "!pip install dotenv\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d11c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google import genai\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from IPython.display import display\n",
    "from dotenv import load_dotenv\n",
    "from google.genai import types\n",
    "load_dotenv()\n",
    "\n",
    "# --- IMPORTANT ---\n",
    "# Paste your API key here. For better security, we recommend using environment variables.\n",
    "# For example: API_KEY=os.environ.get(\"GEMINI_API_KEY\")\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "# -----------------\n",
    "\n",
    "# Configure the client with your API key\n",
    "client = genai.Client(api_key=API_KEY)\n",
    "\n",
    "NANO_BANANA = \"gemini-2.5-flash-image-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f720143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Image as IPImage\n",
    "import pathlib\n",
    "\n",
    "# Loop over all parts and display them either as text or images\n",
    "def display_response(response):\n",
    "  for part in response.parts:\n",
    "    if part.text:\n",
    "      display(Markdown(part.text))\n",
    "    elif image:= part.as_image():\n",
    "      display(image)\n",
    "      # image.show() if not in a notebook\n",
    "\n",
    "# Save the image\n",
    "# If there are multiple ones, only the last one will be saved\n",
    "def save_image(response, path):\n",
    "  for part in response.parts:\n",
    "    if image:= part.as_image():\n",
    "      image.save(path)\n",
    "\n",
    "import dataclasses\n",
    "import numpy as np\n",
    "import base64\n",
    "import json\n",
    "from typing import Tuple\n",
    "\n",
    "@dataclasses.dataclass(frozen=True)\n",
    "class RoomData:\n",
    "  \"\"\"A class to hold room data from bounding box detection.\"\"\"\n",
    "  y0: int\n",
    "  x0: int\n",
    "  y1: int\n",
    "  x1: int\n",
    "  label: str\n",
    "  dimensions: str\n",
    "  \n",
    "def parse_json(json_output: str):\n",
    "    \"\"\"Parses JSON output from the model, removing markdown fencing.\"\"\"\n",
    "    if \"```json\" in json_output:\n",
    "        json_output = json_output.split(\"```json\")[1].split(\"```\")[0]\n",
    "    try:\n",
    "        return json.loads(json_output)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Warning: Could not parse JSON: {json_output}\")\n",
    "        return []\n",
    "    \n",
    "\n",
    "def parse_room_data(\n",
    "    predicted_str: str, *, img_height: int, img_width: int, expand_percent: int = 0\n",
    ") -> list[RoomData]:\n",
    "  \"\"\"Parses the model's string output to a list of RoomData objects.\"\"\"\n",
    "  items = parse_json(predicted_str)\n",
    "  rooms = []\n",
    "  for item in items:\n",
    "    try:\n",
    "        y0 = int(item[\"box_2d\"][0] / 1000 * img_height)\n",
    "        x0 = int(item[\"box_2d\"][1] / 1000 * img_width)\n",
    "        y1 = int(item[\"box_2d\"][2] / 1000 * img_height)\n",
    "        x1 = int(item[\"box_2d\"][3] / 1000 * img_width)\n",
    "\n",
    "        if y0 >= y1 or x0 >= x1:\n",
    "            continue\n",
    "\n",
    "        # Expand the bounding box\n",
    "        if expand_percent > 0:\n",
    "            dx = (x1 - x0) * (expand_percent / 100) / 2\n",
    "            dy = (y1 - y0) * (expand_percent / 100) / 2\n",
    "            x0 = max(0, int(x0 - dx))\n",
    "            y0 = max(0, int(y0 - dy))\n",
    "            x1 = min(img_width, int(x1 + dx))\n",
    "            y1 = min(img_height, int(y1 + dy))\n",
    "\n",
    "        label = item.get(\"label\", \"Unknown\")\n",
    "        dimensions = item.get(\"dimensions\", \"N/A\")\n",
    "        rooms.append(RoomData(y0, x0, y1, x1, label, dimensions))\n",
    "    except (KeyError, IndexError) as e:\n",
    "        print(f\"Skipping an item due to parsing error: {e}\")\n",
    "        continue\n",
    "  return rooms\n",
    "\n",
    "def create_isolated_floor_plan_from_bbox(original_plan: Image.Image, bbox: tuple) -> Image.Image:\n",
    "    \"\"\"Creates an isolated floor plan by cropping to the bounding box.\"\"\"\n",
    "    # bbox is (x0, y0, x1, y1)\n",
    "    return original_plan.crop(bbox)\n",
    "\n",
    "\n",
    "\n",
    "def overlay_bounding_boxes_on_image(image: Image.Image, rooms: list) -> Image.Image:\n",
    "    \"\"\"Overlays bounding boxes on an image for visualization.\"\"\"\n",
    "    from PIL import ImageDraw, ImageColor\n",
    "    \n",
    "    overlay_image = image.copy().convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(overlay_image)\n",
    "    \n",
    "    colors = ['red', 'green', 'blue', 'yellow', 'purple', 'orange']\n",
    "    \n",
    "    for i, room in enumerate(rooms):\n",
    "        color = colors[i % len(colors)]\n",
    "        \n",
    "        # Draw bounding box\n",
    "        draw.rectangle(\n",
    "            ((room.x0, room.y0), (room.x1, room.y1)),\n",
    "            outline=color,\n",
    "            width=3\n",
    "        )\n",
    "        try:\n",
    "            # Attempt to load a font, fallback to default if not available\n",
    "            from PIL import ImageFont\n",
    "            font = ImageFont.load_default(size=16)\n",
    "        except Exception:\n",
    "            font = None\n",
    "        draw.text((room.x0 + 5, room.y0 + 5), room.label, fill=color, font=font)\n",
    "        \n",
    "    return overlay_image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb09ea22",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9633850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "import uuid\n",
    "import time\n",
    "import pathlib\n",
    "\n",
    "# --- Pipeline Inputs ---\n",
    "FLOOR_PLAN_IMAGE = \"../plans/plan5.png\"\n",
    "STYLE = \"2020 modern and minimalist\"\n",
    "# ---------------------\n",
    "\n",
    "# Create a directory to store the output images\n",
    "output_dir = \"property_tour\"\n",
    "pathlib.Path(output_dir).mkdir(exist_ok=True)\n",
    "\n",
    "# Display the input floor plan\n",
    "print(\"Input Floor Plan:\")\n",
    "display(Image.open(FLOOR_PLAN_IMAGE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d2170d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Detect rooms using bounding boxes ---\n",
    "\n",
    "print(\"Step 1: Detecting rooms on floor plan...\")\n",
    "\n",
    "class RoomSegment(BaseModel):\n",
    "    \"\"\"Represents a single detected room from the floor plan.\"\"\"\n",
    "    label: str = Field(description=\"A descriptive name for the room (e.g., 'Living Room', 'Bedroom 1').\")\n",
    "    box_2d: list[int] = Field(description=\"The 2D bounding box coordinates [y0, x0, y1, x1].\")\n",
    "    dimensions: str = Field(description=\"The inferred dimensions of the room as a string (e.g., '13ft 4in x 9ft 0in').\")\n",
    "\n",
    "segmentation_prompt = \"\"\"\n",
    "Analyze the provided floor plan. Identify every enclosed area.\n",
    "For each area, provide a bounding box and infer its dimensions from any text labels present.\n",
    "If a space contains multiple functions without walls (e.g., kitchen and dining), label it as a single combined space like \"Kitchen/Dining Area\". \n",
    "The walls are the determining factor for separate rooms. Do combine the kitchen and living room if no wall separates them.\n",
    "Include walls, doors and windows in the bounding box.\n",
    "\"\"\"\n",
    "\n",
    "original_plan_image = Image.open(FLOOR_PLAN_IMAGE).convert(\"RGB\")\n",
    "w, h = original_plan_image.size\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[segmentation_prompt, original_plan_image],\n",
    "    config={\n",
    "        \"response_mime_type\": \"application/json\",\n",
    "        \"response_schema\": list[RoomSegment],\n",
    "        \"temperature\": 0.4,\n",
    "        \"thinking_config\": {\"thinking_budget\": -1}\n",
    "    },\n",
    ")\n",
    "\n",
    "room_detections = parse_room_data(response.text, img_height=h, img_width=w, expand_percent=5)\n",
    "\n",
    "# --- Display bounding boxes for debugging ---\n",
    "print(\"\\nDetection results with bounding boxes overlaid:\")\n",
    "debug_image = overlay_bounding_boxes_on_image(original_plan_image, room_detections)\n",
    "display(debug_image)\n",
    "\n",
    "\n",
    "# --- 2. Process detection results and create room list ---\n",
    "print(\"\\nStep 2: Processing detections and creating isolated floor plans...\")\n",
    "\n",
    "class Room:\n",
    "    def __init__(self, name, bbox, dimensions):\n",
    "        self.room_id = str(uuid.uuid4())[:8]\n",
    "        self.room_name = name\n",
    "        self.bbox = bbox # (x0, y0, x1, y1)\n",
    "        self.dimensions = dimensions\n",
    "        self.isolated_plan_path = f\"{output_dir}/{self.room_id}_plan.png\"\n",
    "        self.unfurnished_iso_path = f\"{output_dir}/{self.room_id}_unfurnished_iso.png\"\n",
    "        self.furnished_iso_path = f\"{output_dir}/{self.room_id}_furnished_iso.png\"\n",
    "\n",
    "room_list = [Room(name=rd.label, bbox=(rd.x0, rd.y0, rd.x1, rd.y1), dimensions=rd.dimensions) for rd in room_detections]\n",
    "\n",
    "for room in room_list:\n",
    "    print(f\"- Found Room: {room.room_name} (ID: {room.room_id}, Dimensions: {room.dimensions})\")\n",
    "    isolated_image = create_isolated_floor_plan_from_bbox(original_plan_image, room.bbox)\n",
    "    isolated_image.save(room.isolated_plan_path)\n",
    "    print(f\"  -> Saved isolated plan to {room.isolated_plan_path}\")\n",
    "    display(isolated_image)\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# --- 3. Generate textual description of the decoration style ---\n",
    "print(f\"\\nStep 3: Generating style description for '{STYLE}'...\")\n",
    "style_prompt = f\"\"\"\n",
    "Generate a detailed, concise description for a '{STYLE}' interior design style. Focus on:\n",
    "- Color palette\n",
    "- Furniture style (materials, shapes)\n",
    "- Lighting and accessories\n",
    "This will guide image generation. Do not add any intro or outro.\n",
    "\"\"\"\n",
    "response = client.models.generate_content(model=\"gemini-2.5-flash\", contents=style_prompt)\n",
    "style_description = response.text\n",
    "print(\"Style Description Generated:\")\n",
    "display(Markdown(style_description))\n",
    "\n",
    "\n",
    "# --- 4. Generate views for each room and assemble the final property ---\n",
    "print(\"\\nStep 4: Generating individual room views...\")\n",
    "\n",
    "for room in room_list:\n",
    "    print(f\"\\n--- Processing Room: {room.room_name} ({room.room_id}) ---\")\n",
    "    \n",
    "    # 4a. Generate unfurnished isometric view from the isolated plan\n",
    "    print(f\"  4a. Generating unfurnished 3D view for {room.room_name}...\")\n",
    "    unfurnished_iso_prompt = f\"\"\"\n",
    "    Generate a clean, unfurnished 3D isometric view of the room shown in this cropped floor plan.\n",
    "    The room is the '{room.room_name}' and its dimensions are approximately {room.dimensions}. Only model the room itself. Walls are the boundaries.\n",
    "    - Show only the walls and floor based on the visible plan. Do not invent any new walls or structures.\n",
    "    - Do not include any furniture, decorations, or ceiling. Only include equipment if clearly shown in the plan.\n",
    "    - The background must be plain white.\n",
    "    - Do not add any text or labels to the image.\n",
    "    - Pay close attention to the placement of doors and windows from the plan.\n",
    "    \"\"\"\n",
    "    response = client.models.generate_content(\n",
    "        model=NANO_BANANA,\n",
    "        contents=[unfurnished_iso_prompt, original_plan_image, Image.open(room.isolated_plan_path)]\n",
    "    )\n",
    "    save_image(response, room.unfurnished_iso_path)\n",
    "    print(f\"  -> Saved to {room.unfurnished_iso_path}\")\n",
    "    display(Image.open(room.unfurnished_iso_path))\n",
    "    time.sleep(5)\n",
    "\n",
    "    # 4b. Decorate and furnish the room\n",
    "    print(f\"  4b. Furnishing {room.room_name} in '{STYLE}' style...\")\n",
    "    furnish_prompt = f\"\"\"\n",
    "    Take this unfurnished 3D isometric view of the '{room.room_name}' and furnish it completely according to the style description below.\n",
    "    The final image must be a photorealistic, beautifully decorated room. Maintain perfect consistency with the room's structure (walls, windows).\n",
    "\n",
    "    Style Description:\n",
    "    {style_description}\n",
    "    \"\"\"\n",
    "    response = client.models.generate_content(\n",
    "        model=NANO_BANANA,\n",
    "        contents=[furnish_prompt, Image.open(room.unfurnished_iso_path)]\n",
    "    )\n",
    "    save_image(response, room.furnished_iso_path)\n",
    "    print(f\"  -> Saved to {room.furnished_iso_path}\")\n",
    "    display(Image.open(room.furnished_iso_path))\n",
    "    time.sleep(5)\n",
    "\n",
    "    # 4c. Generate interior eye-level views\n",
    "    print(f\"  4c. Generating interior shots for {room.room_name}...\")\n",
    "    interior_shot_prompt = f\"\"\"\n",
    "    Based on this furnished isometric view of the '{room.room_name}', generate photorealistic, human-eye-level images from inside the room, each from a different angle.\n",
    "    These should look like professional real estate photos. Maintain extreme consistency in style, furniture, and colors with the provided isometric view.\n",
    "    Place yourself as a human in the room, looking around. RESPECTING THIS VIEW ANGLE AND LAYOUT IS CRUCIAL.\n",
    "    \"\"\"\n",
    "    response = client.models.generate_content(\n",
    "        model=NANO_BANANA,\n",
    "        contents=[interior_shot_prompt, Image.open(room.furnished_iso_path)]\n",
    "    )\n",
    "    for i, part in enumerate(response.parts):\n",
    "        if image := part.as_image():\n",
    "            interior_shot_path = f\"{output_dir}/{room.room_id}_interior_{i+1}.png\"\n",
    "            image.save(interior_shot_path)\n",
    "            print(f\"  -> Saved interior shot {i+1} to {interior_shot_path}\")\n",
    "            display(Image.open(interior_shot_path))\n",
    "    time.sleep(5)\n",
    "\n",
    "# --- 5. Generate the final assembled 3D isometric view ---\n",
    "print(\"\\nStep 5: Generating final assembled 3D view of the full property...\")\n",
    "\n",
    "assembly_prompt_parts = [\n",
    "    f\"\"\"\n",
    "    Assemble a single, complete 3D isometric view of the entire property.\n",
    "    Use the original floor plan for the overall layout and positioning.\n",
    "    Use the following furnished isometric room views to fill in the details for each corresponding room.\n",
    "    The final image must be a cohesive, photorealistic, and beautifully decorated view of the entire floor, with all rooms furnished as shown in their individual images.\n",
    "    Ensure all rooms are correctly placed and oriented relative to each other, as per the original floor plan.\n",
    "    \"\"\",\n",
    "    Image.open(FLOOR_PLAN_IMAGE)\n",
    "]\n",
    "\n",
    "# Add all the furnished room images to the prompt\n",
    "for room in room_list:\n",
    "    assembly_prompt_parts.append(Image.open(room.furnished_iso_path))\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=NANO_BANANA,\n",
    "    contents=assembly_prompt_parts\n",
    ")\n",
    "\n",
    "final_isometric_view_path = f\"{output_dir}/final_full_furnished_view.png\"\n",
    "save_image(response, final_isometric_view_path)\n",
    "\n",
    "print(\"Final assembled view generated and saved.\")\n",
    "display(Image.open(final_isometric_view_path))\n",
    "\n",
    "print(\"\\n--- Pipeline execution complete! ---\")\n",
    "print(f\"All generated images are saved in the '{output_dir}' directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
